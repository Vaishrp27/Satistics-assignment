{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj53iLCuyEn6"
      },
      "outputs": [],
      "source": [
        "#1.Write a Python program to perform a Z-test for comparing a sample mean to a known population mean and interpret the results\n",
        " import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "        sample (array-like): Sample data\n",
        "        pop_mean (float): Known population mean\n",
        "        pop_std (float): Known population standard deviation\n",
        "        alpha (float): Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "        z_stat (float): Calculated Z statistic\n",
        "        p_value (float): Two-tailed p-value\n",
        "        interpretation (str): Interpretation of the test result\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    # Calculate standard error\n",
        "    se = pop_std / np.sqrt(n)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Simulate random data to perform hypothesis testing and calculate the corresponding P-value using Python@\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Parameters for population\n",
        "pop_mean = 50\n",
        "pop_std = 10\n",
        "\n",
        "# Simulate a sample of size n from a normal distribution\n",
        "n = 30\n",
        "sample = np.random.normal(loc=pop_mean, scale=pop_std, size=n)\n",
        "\n",
        "# Assume we want to test if sample mean differs from 52 (null hypothesis mean)\n",
        "test_mean = 52\n",
        "\n",
        "# Calculate sample mean and standard error\n",
        "sample_mean = np.mean(sample)\n",
        "se = pop_std / np.sqrt(n)  # Using population std since this is Z-test\n",
        "\n",
        "# Calculate Z statistic\n",
        "z_stat = (sample_mean - test_mean) / se\n",
        "\n",
        "# Calculate two-tailed p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
        "\n",
        "print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "print(f\"Z Statistic: {z_stat:.3f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject null hypothesis: sample mean significantly differs from 52\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: no significant difference from 52\")\n"
      ],
      "metadata": {
        "id": "UTrCR3P4yhRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.@ Implement a one-sample Z-test using Python to compare the sample mean with the population mean\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def one_sample_z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    se = pop_std / np.sqrt(n)  # Standard error\n",
        "\n",
        "    # Calculate Z statistic\n",
        "    z_stat = (sample_mean - pop_mean) / se\n",
        "\n",
        "    # Calculate two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Decision\n",
        "    if p_value < alpha:\n",
        "        result = \"Reject null hypothesis: sample mean is significantly different.\"\n",
        "    else:\n",
        "        result = \"Fail to reject null hypothesis: no significant difference.\"\n",
        "\n",
        "    return z_stat, p_value, result\n",
        "\n",
        "# Example usage\n",
        "sample_data = [101, 98, 105, 100, 102, 99, 97, 104]\n",
        "population_mean = 100\n",
        "population_std = 5  # known population std deviation\n",
        "\n",
        "z, p, conclusion = one_sample_z_test(sample_data, population_mean, population_std)\n",
        "\n",
        "print(f\"Z statistic: {z:.3f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(conclusion)\n"
      ],
      "metadata": {
        "id": "XCxkHSIXyoFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.@ Perform a two-tailed Z-test using Python and visualize the decision region on a plot@\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def two_tailed_z_test(sample, pop_mean, pop_std, alpha=0.05):\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    se = pop_std / np.sqrt(n)\n",
        "\n",
        "    # Z statistic\n",
        "    z_stat = (sample_mean - pop_mean) / se\n",
        "\n",
        "    # Two-tailed p-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "    # Critical values for rejection region\n",
        "    z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "    # Plot the normal distribution curve\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    y = norm.pdf(x)\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(x, y, label='Standard Normal Distribution')\n",
        "\n",
        "    # Shade rejection regions\n",
        "    plt.fill_between(x, 0, y, where=(x <= -z_critical), color='red', alpha=0.5, label='Reject Region (Left)')\n",
        "    plt.fill_between(x, 0, y, where=(x >= z_critical), color='red', alpha=0.5, label='Reject Region (Right)')\n",
        "\n",
        "    # Shade acceptance region\n",
        "    plt.fill_between(x, 0, y, where=((x > -z_critical) & (x < z_critical)), color='green', alpha=0.3, label='Accept Region')\n",
        "\n",
        "    # Plot the calculated Z statistic\n",
        "    plt.axvline(z_stat, color='blue', linestyle='--', linewidth=2, label=f'Z statistic = {z_stat:.3f}')\n",
        "\n",
        "    plt.title('Two-tailed Z-test: Decision Regions')\n",
        "    plt.xlabel('Z value')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IiOErfoWyvr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Create a Python function that calculates and visualizes Type 1 and Type 2 errors during hypothesis testing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_type1_type2_errors(pop_mean_null, pop_mean_alt, pop_std, sample_size, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualize Type I and Type II errors for a one-sample Z-test.\n",
        "\n",
        "    Parameters:\n",
        "        pop_mean_null (float): Mean under the null hypothesis H0\n",
        "        pop_mean_alt (float): Mean under the alternative hypothesis H1\n",
        "        pop_std (float): Population standard deviation (assumed known)\n",
        "        sample_size (int): Number of observations in the sample\n",
        "        alpha (float): Significance level (Type I error rate)\n",
        "    \"\"\"\n",
        "    se = pop_std / np.sqrt(sample_size)\n",
        "\n",
        "    # Critical Z value (two-tailed test)\n",
        "    z_critical = norm.ppf(1 - alpha/2)\n",
        "\n",
        "    # Critical sample mean boundaries for rejecting H0\n",
        "    crit_low = pop_mean_null - z_critical * se\n",
        "    crit_high = pop_mean_null + z_critical * se\n",
        "\n",
        "    # X values for plotting\n",
        "    x_min = min(pop_mean_null, pop_mean_alt) - 4*se\n",
        "    x_max = max(pop_mean_null, pop_mean_alt) + 4*se\n",
        "    x = np.linspace(x_min, x_max, 1000)\n",
        "\n",
        "    # PDFs under H0 and H1\n",
        "    pdf_null = norm.pdf(x, loc=pop_mean_null, scale=se)\n",
        "    pdf_alt = norm.pdf(x, loc=pop_mean_alt, scale=se)\n",
        "\n",
        "    plt.figure(figsize=(12,6))\n",
        "\n",
        "    # Plot null hypothesis distribution\n",
        "    plt.plot(x, pdf_null, label='Null Hypothesis (H0)', color='blue')\n",
        "    # Plot alternative hypothesis distribution\n",
        "    plt.plot(x, pdf_alt, label='Alternative Hypothesis (H1)', color='green')\n",
        "\n",
        "    # Shade Type I error regions (reject H0 when true)\n",
        "    plt.fill_between(x, 0, pdf_null, where=(x < crit_low) | (x > crit_high), color='red', alpha=0.3, label='Type I Error (α)')\n",
        "\n",
        "    # Shade Type II error region (fail to reject H0 when false)\n",
        "    plt.fill_between(x, 0, pdf_alt, where=(x >= crit_low) & (x <= crit_high), color='orange', alpha=0.3, label='Type II Error (β)')\n",
        "\n",
        "    # Draw critical boundaries\n",
        "    plt.axvline(crit_low, color='red', linestyle='--', label=f'Critical Values ±{z_critical:.2f}σ')\n",
        "    plt.axvline(crit_high, color='red', linestyle='--')\n",
        "\n",
        "    # Draw population means\n",
        "    plt.axvline(pop_mean_null, color='blue', linestyle=':', label='Mean under H0')\n",
        "    plt.axvline(pop_mean_alt, color='green', linestyle=':', label='Mean under H1')\n",
        "\n",
        "    # Calculate Type II error (β)\n",
        "    beta_low = norm.cdf(crit_high, loc=pop_mean_alt, scale=se) - norm.cdf(crit_low, loc=pop_mean_alt, scale=se)\n",
        "    # Type I error is alpha by definition\n",
        "\n",
        "    plt.title('Type I and Type II Errors in Hypothesis Testing')\n",
        "    plt.xlabel('Sample Mean')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Type I error rate (α): {alpha:.3f}\")\n",
        "    print(f\"Type II error rate (β): {beta_low:.3f}\")\n",
        "    print(f\"Power of test (1 - β): {1 - beta_low:.3f}\")\n",
        "\n",
        "# Example usage\n",
        "plot_type1_type2_errors(\n",
        "    pop_mean_null=100,      # Null hypothesis mean\n",
        "    pop_mean_alt=105,       # Alternative hypothesis mean\n",
        "    pop_std=15,             # Population std dev\n",
        "    sample_size=30,\n",
        "    alpha=0.05\n",
        ")\n"
      ],
      "metadata": {
        "id": "zPk50Xmey3jT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.Write a Python program to perform an independent T-test and interpret the results\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "def independent_t_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform an independent two-sample T-test and interpret the results.\n",
        "\n",
        "    Parameters:\n",
        "        sample1 (array-like): First sample data\n",
        "        sample2 (array-like): Second sample data\n",
        "        alpha (float): Significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "        t_stat (float): T statistic\n",
        "        p_value (float): p-value\n",
        "        interpretation (str): Conclusion of the test\n",
        "    \"\"\"\n",
        "    t_stat, p_value = ttest_ind(sample1, sample2, equal_var=False)  # Welch’s t-test\n",
        "\n",
        "    if p_value < alpha:\n",
        "        interpretation = \"Reject null hypothesis: The two sample means are significantly different.\"\n",
        "    else:\n",
        "        interpretation = \"Fail to reject null hypothesis: No significant difference between the sample means.\"\n",
        "\n",
        "    return t_stat, p_value, interpretation\n",
        "\n",
        "# Example usage\n",
        "group1 = [23, 20, 22, 25, 30, 27]\n",
        "group2 = [31, 35, 29, 32, 30, 28]\n",
        "\n",
        "t_stat, p_val, result = independent_t_test(group1, group2)\n",
        "\n",
        "print(f\"T statistic: {t_stat:.3f}\")\n",
        "print(f\"P-value: {p_val:.4f}\")\n",
        "print(f\"Result: {result}\")\n"
      ],
      "metadata": {
        "id": "PojkYBCoy-8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.Perform a paired sample T-test using Python and visualize the comparison results\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "def paired_sample_t_test(before, after, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Performs a paired sample t-test and visualizes results.\n",
        "\n",
        "    Parameters:\n",
        "        before (array-like): Sample data before treatment\n",
        "        after (array-like): Sample data after treatment\n",
        "        alpha (float): Significance level\n",
        "\n",
        "    Returns:\n",
        "        t_stat (float): t statistic\n",
        "        p_value (float): p-value\n",
        "        interpretation (str): Conclusion of the test\n",
        "    \"\"\"\n",
        "    t_stat, p_value = ttest_rel(before, after)\n",
        "\n",
        "    if p_value < alpha:\n",
        "        interpretation = \"Reject null hypothesis: Significant difference between paired samples.\"\n",
        "    else:\n",
        "        interpretation = \"Fail to reject null hypothesis: No significant difference between paired samples.\"\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(8,6))\n",
        "\n",
        "    # Boxplot of before and after\n",
        "    plt.boxplot([before, after], labels=['Before', 'After'])\n",
        "\n",
        "    # Connect paired s\n"
      ],
      "metadata": {
        "id": "nIAGqklAzKX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Simulate data and perform both Z-test and T-test, then compare the results using Python\n",
        "import numpy as np\n",
        "from scipy.stats import norm, ttest_1samp\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(123)\n",
        "\n",
        "# Population parameters (known)\n",
        "pop_mean = 100\n",
        "pop_std = 15\n",
        "\n",
        "# Sample size and simulated data\n",
        "n = 30\n",
        "sample = np.random.normal(loc=pop_mean + 2, scale=pop_std, size=n)  # mean shifted by +2\n",
        "\n",
        "# Hypothesized mean to test against\n",
        "test_mean = pop_mean\n",
        "\n",
        "# --- One-sample Z-test ---\n",
        "sample_mean = np.mean(sample)\n",
        "se_z = pop_std / np.sqrt(n)\n",
        "z_stat = (sample_mean - test_mean) / se_z\n",
        "p_value_z = 2 * (1 - norm.cdf(abs(z_stat)))\n",
        "\n",
        "# --- One-sample T-test ---\n",
        "t_stat, p_value_t = ttest_1samp(sample, test_mean)\n",
        "\n",
        "# Results\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"\\n--- One-sample Z-test ---\")\n",
        "print(f\"Z statistic: {z_stat:.4f}\")\n",
        "print(f\"P-value: {p_value_z:.4f}\")\n",
        "\n",
        "print(\"\\n--- One-sample T-test ---\")\n",
        "print(f\"T statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value_t:.4f}\")\n",
        "\n",
        "# Interpretation (alpha = 0.05)\n",
        "alpha = 0.05\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"Z-test:\", \"Reject H0\" if p_value_z < alpha else \"Fail to reject H0\")\n",
        "print(\"T-test:\", \"Reject H0\" if p_value_t < alpha else \"Fail to reject H0\")\n"
      ],
      "metadata": {
        "id": "fbw1wgcqzQHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9.Write a Python function to calculate the confidence interval for a sample mean and explain its significance.\n",
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "def confidence_interval(sample, confidence=0.95, pop_std=None):\n",
        "    \"\"\"\n",
        "    Calculate the confidence interval for the sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        sample (array-like): Sample data\n",
        "        confidence (float): Confidence level (default 0.95)\n",
        "        pop_std (float or None): Population std dev if known; if None, use sample std dev and t-distribution\n",
        "\n",
        "    Returns:\n",
        "        (lower_bound, upper_bound): Tuple with confidence interval bounds\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "\n",
        "    if pop_std is not None:\n",
        "        # Use Z-distribution when population std dev is known\n",
        "        se = pop_std / np.sqrt(n)\n",
        "        z_crit = norm.ppf((1 + confidence) / 2)\n",
        "        margin_error = z_crit * se\n",
        "    else:\n",
        "        # Use T-distribution when population std dev unknown\n",
        "        sample_std = np.std(sample, ddof=1)\n",
        "        se = sample_std / np.sqrt(n)\n",
        "        t_crit = t.ppf((1 + confidence) / 2, df=n-1)\n",
        "        margin_error = t_crit * se\n",
        "\n",
        "    lower_bound = sample_mean - margin_error\n",
        "    upper_bound = sample_mean + margin_error\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage\n",
        "data = [12, 15, 14, 16, 13, 14, 15, 16, 14, 13]\n",
        "ci_lower, ci_upper = confidence_interval(data, confidence=0.95)\n",
        "\n",
        "print(f\"95% Confidence Interval: ({ci_lower:.2f}, {ci_upper:.2f})\")\n"
      ],
      "metadata": {
        "id": "cK_eHN03zYVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.Write a Python program to calculate the margin of error for a given confidence level using sample data\n",
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "def margin_of_error(sample, confidence=0.95, pop_std=None):\n",
        "    \"\"\"\n",
        "    Calculate the margin of error for a sample mean.\n",
        "\n",
        "    Parameters:\n",
        "        sample (array-like): Sample data\n",
        "        confidence (float): Confidence level (default 0.95)\n",
        "        pop_std (float or None): Population std dev if known; else use sample std dev\n",
        "\n",
        "    Returns:\n",
        "        float: Margin of error\n",
        "    \"\"\"\n",
        "    n = len(sample)\n",
        "\n",
        "    if pop_std is not None:\n",
        "        # Use Z-distribution\n",
        "        se\n"
      ],
      "metadata": {
        "id": "4F7P4wCUziTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. Implement a Bayesian inference method using Bayes' Theorem in Python and explain the process\n",
        "def bayes_theorem(prior, likelihood, evidence):\n",
        "    \"\"\"\n",
        "    Calculate the posterior probability using Bayes' Theorem.\n",
        "\n",
        "    Parameters:\n",
        "        prior (float): Prior probability P(H)\n",
        "        likelihood (float): Likelihood P(E|H)\n",
        "        evidence (float): Total probability of evidence P(E)\n",
        "\n",
        "    Returns:\n",
        "        float: Posterior probability P(H|E)\n",
        "    \"\"\"\n",
        "    posterior = (likelihood * prior) / evidence\n",
        "    return posterior\n",
        "\n",
        "# Example: Medical test scenario\n",
        "# H = patient has the disease\n",
        "# E = test result is positive\n",
        "\n",
        "prior = 0.01               # P(H) = 1% prevalence of disease\n",
        "likelihood = 0.9           # P(E|H) = 90% test sensitivity\n",
        "false_positive_rate = 0.05 # P(E|not H) = 5% false positive rate\n",
        "\n",
        "# Total probability of positive test result (evidence)\n",
        "evidence = likelihood * prior + false_positive_rate * (1 - prior)\n",
        "\n",
        "posterior = bayes_theorem(prior, likelihood, evidence)\n",
        "\n",
        "print(f\"Posterior probability (patient has disease given positive test): {posterior:.4f}\")\n"
      ],
      "metadata": {
        "id": "QzQHwbDuzrYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12.D Perform a Chi-square test for independence between two categorical variables in Python\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample data: Survey of people who prefer coffee or tea across age groups\n",
        "data = {\n",
        "    '18-29': [30, 20],\n",
        "    '30-49': [40, 35],\n",
        "    '50+': [20, 25]\n",
        "}\n",
        "# Rows = Beverage preference (Coffee, Tea)\n",
        "# Columns = Age groups\n",
        "contingency_table = pd.DataFrame(data, index=['Coffee', 'Tea'])\n",
        "\n",
        "print(\"Contingency Table:\")\n",
        "print(contingency_table)\n",
        "\n",
        "# Perform Chi-square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "# Display results\n",
        "print(f\"\\nChi-square Statistic: {chi2:.4f}\")\n",
        "print(f\"P-value: {p:.4f}\")\n",
        "print(f\"Degrees of Freedom: {dof}\")\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(pd.DataFrame(expected, index=contingency_table.index, columns=contingency_table.columns))\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"\\nConclusion: Reject null hypothesis — there is a significant association between age group and beverage preference.\")\n",
        "else:\n",
        "    print(\"\\nConclusion: Fail to reject null hypothesis — no significant association between age group and beverage preference.\")\n"
      ],
      "metadata": {
        "id": "4gTzASLkzy0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13.Write a Python program to calculate the expected frequencies for a Chi-square test based on observed dataD\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Sample observed data: Preferences by gender\n",
        "data = {\n",
        "    'Like': [60, 40],\n",
        "    'Dislike': [30, 70]\n",
        "}\n",
        "# Rows = Gender (Male, Female)\n",
        "# Columns = Response (Like, Dislike)\n",
        "observed = pd.DataFrame(data, index=['Male', 'Female'])\n",
        "\n",
        "print(\"Observed Frequencies:\")\n",
        "print(observed)\n",
        "\n",
        "# Calculate expected frequencies using chi2_contingency\n",
        "chi2, p, dof, expected = chi2_contingency(observed)\n",
        "\n",
        "# Convert expected frequencies to DataFrame for display\n",
        "expected_df = pd.DataFrame(expected, index=observed.index, columns=observed.columns)\n",
        "\n",
        "print(\"\\nExpected Frequencies:\")\n",
        "print(expected_df.round(2))\n"
      ],
      "metadata": {
        "id": "5Z7s4e1Y0ENb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14.D Perform a goodness-of-fit test using Python to compare the observed data to an expected distribution\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Observed frequencies from a 6-sided die rolled 60 times\n",
        "observed = np.array([8, 9, 10, 11, 12, 10])  # example data\n",
        "\n",
        "# Expected frequencies for a fair die (60 rolls → each face expected ~10 times)\n",
        "expected = np.full_like(observed, fill_value=np.sum(observed) / len(observed))\n",
        "\n",
        "# Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Output\n",
        "print(\"Observed Frequencies:\", observed)\n",
        "print(\"Expected Frequencies:\", expected)\n",
        "print(f\"\\nChi-square Statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject null hypothesis — the observed distribution differs significantly from expected.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject null hypothesis — no significant difference from expected distribution.\")\n"
      ],
      "metadata": {
        "id": "qx4_BAa40P5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15.Create a Python script to simulate and visualize the Chi-square distribution and discuss its characteristicsD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "def simulate_chi_square(df=5, num_samples=10000):\n",
        "    \"\"\"\n",
        "    Simulate and visualize a Chi-square distribution.\n",
        "\n",
        "    Parameters:\n",
        "        df (int): Degrees of freedom\n",
        "        num_samples (int): Number of samples to simulate\n",
        "    \"\"\"\n",
        "    # Simulate Chi-square distributed data\n",
        "    chi_square_data = np.random.chisquare(df, size=num_samples)\n",
        "\n",
        "    # Create x values for PDF\n",
        "    x = np.linspace(0, np.max(chi_square_data), 500)\n",
        "    pdf = chi2.pdf(x, df)\n",
        "\n",
        "    # Plot histogram and PDF\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(chi_square_data, bins=50, density=True, alpha=0.6, color='skyblue', label='Simulated data')\n",
        "    plt.plot(x, pdf, 'r-', label=f'Chi-square PDF (df={df})', linewidth=2)\n",
        "    plt.title(f'Chi-square\n"
      ],
      "metadata": {
        "id": "PVWd6Gwd0ZZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16.D Implement an F-test using Python to compare the variances of two random samples\n",
        "import numpy as np\n",
        "from scipy.stats import f\n",
        "\n",
        "def f_test(sample1, sample2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Perform an F-test to compare the variances of two samples.\n",
        "\n",
        "    Parameters:\n",
        "        sample1, sample2: array-like, the two samples to compare\n",
        "        alpha: significance level (default 0.05)\n",
        "\n",
        "    Returns:\n",
        "        f_stat: F statistic\n",
        "        p_value: two-tailed p-value\n",
        "        conclusion: interpretation of the result\n",
        "    \"\"\"\n",
        "    var1 = np.var(sample1, ddof=1)\n",
        "    var2 = np.var(sample2, ddof=1)\n",
        "\n",
        "    # Ensure F >= 1 for consistency\n",
        "    if var1 > var2:\n",
        "        f_stat = var1 / var2\n",
        "        dfn, dfd = len(sample1) - 1, len(sample2) - 1\n",
        "    else:\n",
        "        f_stat = var2 / var1\n",
        "        dfn, dfd = len(sample2) - 1, len(sample1) - 1\n",
        "\n",
        "    # Two-tailed p-value\n",
        "    p_value = 2 * min(\n",
        "        f.cdf(f_stat, dfn, dfd),\n",
        "        1 - f.cdf(f_stat, dfn, dfd)\n",
        "    )\n",
        "\n",
        "    # Interpretation\n",
        "    conclusion = \"Reject null hypothesis: variances are significantly different.\" if p_value < alpha else \"Fail to reject null hypothesis: no significant difference in variances.\"\n",
        "\n",
        "    return f_stat, p_value, conclusion\n",
        "\n",
        "# Example usage: Simulate two samples\n",
        "np.random.seed(42)\n",
        "sample_a = np.random.normal(loc=10, scale=3, size=30)\n",
        "sample_b = np.random.normal(loc=10, scale=5, size=30)\n",
        "\n",
        "f_stat, p_val, result = f_test(sample_a, sample_b)\n",
        "\n",
        "print(\n"
      ],
      "metadata": {
        "id": "pS-SPO9k0iC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Write a Python program to perform an ANOVA test to compare means between multiple groups and interpret the resultsD\n",
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Simulate data for 3 groups (e.g., test scores for 3 different teaching methods)\n",
        "np.random.seed(0)\n",
        "group1 = np.random.normal(loc=70, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=75, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=80, scale=5, size=30)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "# Print results\n",
        "print(\"ANOVA Test Results:\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpreta\n"
      ],
      "metadata": {
        "id": "SwvZ0iu60w3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18.Perform a one-way ANOVA test using Python to compare the means of different groups and plot the results\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Step 1: Simulate data for 3 groups\n",
        "np.random.seed(1)\n",
        "group_A = np.random.normal(loc=70, scale=5, size=30)\n",
        "group_B = np.random.normal(loc=75, scale=5, size=30)\n",
        "group_C = np.random.normal(loc=80, scale=5, size=30)\n",
        "\n",
        "# S\n"
      ],
      "metadata": {
        "id": "np5zr8_k09an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19.Write a Python function to check the assumptions (normality, independence, and equal variance) for ANOVA\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def check_anova_assumptions(*groups):\n",
        "    \"\"\"\n",
        "    Check ANOVA assumptions: normality, independence (informally), and homogeneity of variance.\n",
        "\n",
        "    Parameters:\n",
        "        *groups: Variable-length list of groups (arrays or lists)\n",
        "    \"\"\"\n",
        "    print(\"Assumption Checks for ANOVA:\\n\")\n",
        "\n",
        "    # Combine all groups into one array and labels\n",
        "    data = np.concatenate(groups)\n",
        "    labels = np.concatenate([[f\"Group {i+1}\"] * len(group) for i, group in enumerate(groups)])\n",
        "\n",
        "    # 1. Normality (Shapiro-Wilk Test)\n",
        "    print(\"1. Normality (Shapiro-Wilk Test for each group):\")\n",
        "    for i, group in enumerate(groups):\n",
        "        stat, p = stats.shapiro(group)\n",
        "        print(f\"  Group {i+1}: W={stat:.4f}, p-value={p:.4f} {'(normal)' if p > 0.05 else '(not normal)'}\")\n",
        "\n",
        "    # 2. Homogeneity of Variances (Levene’s Test)\n",
        "    print(\"\\n2. Homogeneity of Variance (Levene’s Test):\")\n",
        "    levene_stat, levene_p = stats.levene(*groups)\n",
        "    print(f\"  Levene’s test: W={levene_stat:.4f}, p-value={levene_p:.4f} {'(equal variances)' if levene_p > 0.05 else '(unequal variances)'}\")\n",
        "\n",
        "    # 3. Independence (assumed from experimental design)\n",
        "    print(\"\\n3. Independence: Must be assumed from study design. Not testable with just data.\\n\")\n",
        "\n",
        "    # Visualization (optional)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    sns.boxplot(x=labels, y=data)\n",
        "    plt.title(\"Boxplot of Groups (Check for\n"
      ],
      "metadata": {
        "id": "r1FN90hT1Soc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20.D Perform a two-way ANOVA test using Python to study the interaction between two factors and visualize the results\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# Simulate a dataset\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'Score': np.random.normal(75, 10, 90),\n",
        "    'Teaching_Method': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
        "    'Study_Hours': (['Low'] * 15 + ['High'] * 15) * 3\n",
        "})\n",
        "\n",
        "# Introduce some effect\n",
        "data.loc[(data['Teaching_Method'] == 'B') & (data['Study_Hours'] == 'High'), 'Score'] += 5\n",
        "data.loc[(data['Teaching_Method'] == 'C') & (data['Study_Hours'] == 'High'), 'Score'] += 10\n",
        "\n",
        "# Two-way ANOVA\n",
        "model = ols('Score ~ C(Teaching_Method) * C(Study_Hours)', data=data).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print(\"Two-Way ANOVA Results:\\n\")\n",
        "print(anova_table)\n",
        "\n",
        "# Visualization: Interaction Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.pointplot(data=data, x='Teaching_Method', y='Score', hue='Study_Hours',\n",
        "              dodge=True, markers=['o', 's'], capsize=.1, errwidth=1, palette='Set2')\n",
        "plt.title(\"Interaction between Teaching Method and Study Hours\")\n",
        "plt.ylabel(\"Average Score\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UT9rqHJL1cEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21.Write a Python program to visualize the F-distribution and discuss its use in hypothesis testing\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "def plot_f_distribution(df1, df2, alpha=0.05):\n",
        "    \"\"\"\n",
        "    Visualizes the F-distribution and marks the critical value for a given alpha.\n",
        "\n",
        "    Parameters:\n",
        "        df1 (int): Degrees of freedom numerator\n",
        "        df2 (int): Degrees of freedom denominator\n",
        "        alpha (float): Significance level\n",
        "    \"\"\"\n",
        "    # Generate x values\n",
        "    x = np.linspace(0, 5, 1000)\n",
        "    y = f.pdf(x, df1, df2)\n",
        "\n",
        "    # Critical value (right-tail test)\n",
        "    critical_value = f.ppf(1 - alpha, df1, df2)\n",
        "\n",
        "    # Plot the F-distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, y, 'b-', label=f'F-distributio\n"
      ],
      "metadata": {
        "id": "JrxVZ5Ph1tKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Perform a one-way ANOVA test in Python and visualize the results with boxplots to compare group means\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f_oneway\n",
        "import seaborn as sns\n",
        "\n",
        "# Simulate sample data for 3 groups\n",
        "np.random.seed(42)\n",
        "group1 = np.random.normal(loc=70, scale=5, size=30)\n",
        "group2 = np.random.normal(loc=75, scale=5, size=30)\n",
        "group3 = np.random.normal(loc=80, scale=5, size=30)\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_stat, p_value = f_oneway(group1, group2, group3)\n",
        "\n",
        "print(\"One-Way ANOVA Test Results\")\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Conclusion: At least one group mean is significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: No significant difference between group means.\")\n",
        "\n",
        "# Prepare data for visualization\n",
        "df = pd.DataFrame({\n",
        "    'Score': np.concatenate([group1, group2, group3]),\n",
        "    'Group': ['Group 1'] * len(group1) + ['Group 2'] * len(group2) + ['Group 3'] * len(group3)\n",
        "})\n",
        "\n",
        "# Create boxplot to compare group distributions\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Group', y='Score', data=df)\n",
        "plt.title('Boxplot of Scores by Group')\n",
        "plt.ylabel('Scores')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EJn8MW891-MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#23.Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the means\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Step 1: Simulate data from two normal distributions\n",
        "np.random.seed(123)\n",
        "group1 = np.random.normal(loc=50, scale=10, size=40)  # mean=50, sd=10\n",
        "group2 = np.random.normal(loc=55, scale=10, size=40)  # mean=55, sd=10\n",
        "\n",
        "# Step 2: Perform independent two-sample t-test (assuming equal variances)\n",
        "t_stat, p_value = ttest_ind(group1, group2, equal_var=True)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(\"Two-Sample Independent t-test Results\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpret the result at alpha = 0.05\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis — means are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis — no significant difference in means.\")\n"
      ],
      "metadata": {
        "id": "wYrw45SG2YKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#24.Simulate random data from a normal distribution, then perform hypothesis testing to evaluate the meansD\n",
        "import numpy as np\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Parameters\n",
        "np.random.seed(0)\n",
        "population_mean = 50   # Known population mean\n",
        "sample_size = 40\n",
        "sample_mean_shift = 52  # True mean for simulated data (to test against population_mean)\n",
        "sample_std = 10\n",
        "\n",
        "# Step 1: Simulate sample data\n",
        "sample_data = np.random.normal(loc=sample_mean_shift, scale=sample_std, size=sample_size)\n",
        "\n",
        "# Step 2: Perform one-sample t-test\n",
        "t_stat, p_value = ttest_1samp(sample_data, popmean=population_mean)\n",
        "\n",
        "# Step 3: Output results\n",
        "print(\"One-Sample t-Test Results\")\n",
        "print(f\"Sample mean: {np.mean(sample_data):.2f}\")\n",
        "print(f\"t-statistic: {t_stat:.4f}\")\n",
        "print(f\"p-value: {p_value:.4f}\")\n",
        "\n",
        "# Step 4: Interpretation\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis — sample mean is significantly different from population mean.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis — no significant difference from population mean.\")\n"
      ],
      "metadata": {
        "id": "emQZMUuK2gn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#25.D Write a Python script to perform a Z-test for comparing proportions between two datasets or groups\n",
        "import numpy as np\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "\n",
        "# Sample data: successes and sample sizes for two groups\n",
        "successes = np.array([45, 30])  # number of successes in group 1 and group 2\n",
        "samples = np.array([100, 80])   # total observations in group 1 and group 2\n",
        "\n",
        "# Perform two-proportion z-test\n",
        "stat, p_value = proportions_ztest(count=successes, nobs=samples)\n",
        "\n",
        "print(\"Two-Proportion Z-Test Results\")\n",
        "print(f\"Z-statistic: {stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpretation at alpha = 0.05\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject null hypothesis — proportions are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject null hypothesis — no significant difference between proportions.\")\n"
      ],
      "metadata": {
        "id": "EDDABOk02wmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#26.Implement an F-test for comparing the variances of two datasets, then interpret and visualize the results\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import f\n",
        "\n",
        "# Simulate two datasets\n",
        "np.random.seed(42)\n",
        "data1 = np.random.normal(loc=0, scale=5, size=30)   # std dev = 5\n",
        "data2 = np.random.normal(loc=0, scale=3, size=30)   # std dev = 3\n",
        "\n",
        "# Calculate sample variances\n",
        "var1 = np.var(data1, ddof=1)\n",
        "var2 = np.var(data2, ddof=1)\n",
        "\n",
        "# Calculate degrees of freedom\n",
        "df1 = len(data1) - 1\n",
        "df2 = len(data2) - 1\n",
        "\n",
        "# Calculate F statistic\n",
        "F = var1 / var2 if var1 > var2 else var2 / var1  # Always put larger variance in numerator\n",
        "\n",
        "# Calculate p-value (two-tailed test)\n",
        "p_value = 2 * min(f.cdf(F, df1, df2), 1 - f.cdf(F, df1, df2))\n",
        "\n",
        "print(f\"Variance of data1: {var1:.4f}\")\n",
        "print(f\"Variance of data2: {var2:.4f}\")\n",
        "print(f\"F-statistic: {F:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject the null hypothesis — variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject the null hypothesis — no significant difference in variances.\")\n",
        "\n",
        "# Visualization: Plot F-distribution and mark critical regions\n",
        "x = np.linspace(0, 5, 1000)\n",
        "y = f.pdf(x, df1, df2)\n",
        "\n",
        "# Critical values for two-tailed test\n",
        "F_critical_low = f.ppf(alpha/2, df1, df2)\n",
        "F_critical_high = f.ppf(1 - alpha/2, df1, df2)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x, y, label='F-distribution')\n",
        "plt.fill_between(x, y, where=(x <= F_critical_low), color='red', alpha=0.5, label='Rejection region (low)')\n",
        "plt.fill_between(x, y, where=(x >= F_critical_high), color='red', alpha=0.5, label='Rejection region (high)')\n",
        "plt.axvline(F, color='blue', linestyle='--', label=f'F statistic = {F:.2f}')\n",
        "plt.axvline(F_critical_low, color='red', linestyle='--', label=f'Critical low = {F_critical_low:.2f}')\n",
        "plt.axvline(F_critical_high, color='red', linestyle='--', label=f'Critical high = {F_critical_high:.2f}')\n",
        "plt.title('F-distribution with Critical Regions for Variance Test')\n",
        "plt.xlabel('F value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GhWa9R-X25VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#27.Perform a Chi-square test for goodness of fit with simulated data and analyze the results.\n",
        "import numpy as np\n",
        "from scipy.stats import chisquare\n",
        "\n",
        "# Step 1: Simulate observed data (counts of categories)\n",
        "# Suppose we have 4 categories\n",
        "observed = np.array([50, 30, 10, 10])\n",
        "\n",
        "# Step 2: Define expected distribution (probabilities) and calculate expected counts\n",
        "# Let's say the expected probabilities are uniform (equal probability for each category)\n",
        "expected_prob = np.array([0.25, 0.25, 0.25, 0.25])\n",
        "total_count = observed.sum()\n",
        "expected = expected_prob * total_count\n",
        "\n",
        "# Step 3: Perform Chi-square goodness-of-fit test\n",
        "chi2_stat, p_value = chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "# Step 4: Output results\n",
        "print(\"Chi-square Goodness-of-Fit Test\")\n",
        "print(f\"Chi-square statistic: {chi2_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Conclusion: Reject null hypothesis — observed distribution differs from expected.\")\n",
        "else:\n",
        "    print(\"Conclusion: Fail to reject null hypothesis — observed distribution fits expected well.\")\n"
      ],
      "metadata": {
        "id": "Hn9Rs4pq3D3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is hypothesis testing in statistics?\n",
        "ans.Hypothesis testing in statistics is a formal method used to make decisions or inferences about a population based on sample data. It helps determine whether there is enough evidence to support a specific claim (hypothesis) about a population parameter.\n",
        "\n",
        "\n",
        "2.What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "ans.The null hypothesis is a default assumption that there is no effect, no difference, or no relationship in the population,The alternative hypothesis is what you want to test or prove.\n",
        "It states that there is an effect, a difference, or a relationship.\n",
        "3.What is the significance level in hypothesis testing, and why is it important?\n",
        "It represents the maximum probability of making a Type I error, which is rejecting the null hypothesis when it is actually true.\n",
        "\n",
        "Commonly set values are 0.05 (5%), 0.01 (1%), or 0.10 (10%).\n",
        "4.What does a P-value represent in hypothesis testing?\n",
        "What is a P-value?\n",
        "A P-value is the probability of obtaining test results at least as extreme as the observed results, assuming the null hypothesis (H₀) is true.\n",
        "<!-- 5.How do you interpret the P-value in hypothesis testing -->\n",
        "Compare the P-value to your significance level (α) — usually 0.05:\n",
        "\n",
        "If P-value ≤ α:\n",
        "The observed data is unlikely under the null hypothesis.\n",
        "Action: Reject the null hypothesis (H₀).\n",
        "Meaning: There is statistically significant evidence to support the alternative hypothesis (H₁).\n",
        "\n",
        "If P-value > α:\n",
        "The observed data is consistent with the null hypothesis.\n",
        "Action: Fail to reject the null hypothesis.\n",
        "Meaning: There is insufficient evidence to support the alternative hypothesis.\n",
        "\n",
        "6.What are Type 1 and Type 2 errors in hypothesis testing\n",
        "Type 1 Error (False Positive)\n",
        "Occurs when you reject the null hypothesis (H₀) even though it is actually true.\n",
        "\n",
        "In other words, you claim there is an effect/difference when there isn’t one.\n",
        "\n",
        "The probability of making a Type 1 error is the significance level (α), commonly 0.05.\n",
        "\n",
        "Example: Concluding a new drug works when it actually doesn’t.\n",
        "\n",
        "Type 2 Error (False Negative)\n",
        "Happens when you fail to reject the null hypothesis (H₀) even though the alternative hypothesis (H₁) is true.\n",
        "\n",
        "You miss detecting a real effect or difference.\n",
        "\n",
        "The probability of making a Type 2 error is denoted by β.\n",
        "\n",
        "The power of a test (1 - β) is the probability of correctly rejecting a false null hypothesis.\n",
        "\n",
        "Example: Concluding a drug doesn’t work when it actually does.\n",
        "\n",
        "7.What is the difference between a one-tailed and a two-tailed test in hypothesis testing\n",
        "One-tailed Test\n",
        "Tests for an effect in only one direction (either greater than or less than).\n",
        "\n",
        "Hypotheses example:\n",
        "\n",
        "H₀: The mean is ≤ 10\n",
        "\n",
        "H₁: The mean is > 10\n",
        "(testing if mean is significantly greater than 10)\n",
        "\n",
        "The critical region (rejection area) is only on one side of the sampling distribution.\n",
        "\n",
        "Used when you have a specific direction in mind.\n",
        "\n",
        "Two-tailed Test\n",
        "Tests for an effect in both directions (whether greater or less than).\n",
        "\n",
        "Hypotheses example:\n",
        "\n",
        "H₀: The mean = 10\n",
        "\n",
        "H₁: The mean ≠ 10\n",
        "(testing if mean is significantly different from 10, either higher or lower)\n",
        "\n",
        "The critical region is split between both tails of the sampling distribution.\n",
        "\n",
        "Used when you want to detect any difference, regardless of direction.\n",
        "8.What is the Z-test, and when is it used in hypothesis testing\n",
        "A Z-test is a statistical test used to determine whether there is a significant difference between the sample mean and a known population mean (or between two means) when the population variance is known or the sample size is large (typically n > 30).\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "A Z-score (or standard score) measures how many standard deviations a data point (or sample mean) is from the population mean.\n",
        "10.@ What is the T-distribution, and when should it be used instead of the normal distribution\n",
        "What is the T-distribution?\n",
        "The T-distribution (or Student’s t-distribution) is a probability distribution that is similar to the normal distribution but has heavier tails. This means it accounts for more variability, especially in the extremes.\n",
        "\n",
        "When should you use the T-distribution instead of the Normal distribution?\n",
        "When the sample size is small (usually\n",
        "𝑛\n",
        "<\n",
        "30\n",
        "n<30).\n",
        "\n",
        "When the population standard deviation (σ) is unknown and must be estimated from the sample.\n",
        "11.@ What is the T-distribution, and when should it be used instead of the normal distribution\n",
        "11.What is the difference between a Z-test and a T-test\n",
        "\n",
        "\n",
        "It adjusts for extra uncertainty due to estimating the standard deviation from limited data.\n",
        "11.\n"
      ],
      "metadata": {
        "id": "oalaQA6M3NoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What is the difference between a Z-test and a T-test\n",
        "Use Z-test when you know the population standard deviation or have a large sample.\n",
        "\n",
        "Use T-test when the population standard deviation is unknown and/or the sample size is small, so you estimate variability from your sample\n",
        "12.What is a T-test?\n",
        "A T-test is a statistical test used to determine whether there is a significant difference between the means of two groups or between a sample mean and a population mean when the population standard deviation is unknown and the sample size is small.\n",
        "\n",
        "It uses the Student’s T-distribution, which accounts for extra uncertainty due to estimating the standard deviation from the sample.\n",
        "\n",
        "13.What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "Relationship Between Z-test and T-test:\n",
        "Both tests are used to compare sample means to a population mean or to compare means between groups.\n",
        "\n",
        "The main difference lies in whether the population standard deviation (σ) is known:\n",
        "\n",
        "If σ is known (or sample size is large enough to approximate it), you use a Z-test.\n",
        "\n",
        "If σ is unknown and estimated from the sample, especially with a small sample size (n < 30), you use a T-test.\n",
        "14.What is a confidence interval, and how is it used to interpret statistical results\n",
        "A confidence interval is a range of values, calculated from sample data, that is likely to contain the true population parameter (e.g., mean) with a certain level of confidence.\n",
        "\n",
        "For example, a 95% confidence interval means that if you repeated the sampling many times, approximately 95% of those intervals would contain the true population mean\n",
        "15.What is the margin of error, and how does it affect the confidence interval?\n",
        "The Margin of Error is the amount added and subtracted from the sample estimate to create the confidence interval. It represents the maximum expected difference between the true population parameter and the sample estimate due to sampling variability.\n",
        "16.How is Bayes' Theorem used in statistics, and what is its significance\n",
        "Bayes’ Theorem describes how to update the probability of a hypothesis based on new evidence or data. It’s a foundational concept in Bayesian statistics\n",
        "17.What is the Chi-square distribution, and when is it used\n",
        "The Chi-square distribution is a continuous probability distribution that arises from the sum of the squares of independent standard normal random variables.\n",
        "18.What is the Chi-square goodness of fit test, and how is it applied?\n",
        "The Chi-square goodness-of-fit test is a statistical test used to determine whether observed categorical data matches an expected distribution.\n",
        "19.What is the F-distribution, and when is it used in hypothesis testing\n",
        "The F-distribution is a continuous probability distribution that arises as the ratio of two scaled chi-square distributions. It is characterized by two sets of degrees of freedom\n",
        "20.What is an ANOVA test, and what are its assumptions?\n",
        "ANOVA stands for Analysis of Variance. It is a statistical method used to compare the means of three or more independent groups to see if at least one group mean differs significantly from the others.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ke3jzE8l5rSC"
      }
    }
  ]
}